{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d11de408-0405-4f29-84d0-9d39a1319428",
      "metadata": {
        "tags": [],
        "id": "d11de408-0405-4f29-84d0-9d39a1319428",
        "outputId": "9730d8b0-feb4-4763-c43e-a05fc3cdb364"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in ./mambaforge/envs/env/lib/python3.11/site-packages (2.3.1)\n",
            "Requirement already satisfied: filelock in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torchvision in ./mambaforge/envs/env/lib/python3.11/site-packages (0.18.1)\n",
            "Requirement already satisfied: numpy in ./mambaforge/envs/env/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch in ./mambaforge/envs/env/lib/python3.11/site-packages (from torchvision) (2.3.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: filelock in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch->torchvision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch->torchvision) (1.12.1)\n",
            "Requirement already satisfied: networkx in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch->torchvision) (2024.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from jinja2->torch->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from sympy->torch->torchvision) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6300f462-0c89-44ac-b114-563058e5f116",
      "metadata": {
        "tags": [],
        "id": "6300f462-0c89-44ac-b114-563058e5f116"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13031260-d297-47de-ad7b-ff46454b295c",
      "metadata": {
        "tags": [],
        "id": "13031260-d297-47de-ad7b-ff46454b295c",
        "outputId": "43d1250e-bc55-4013-dd17-6176b0a7d12f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch-geometric in ./mambaforge/envs/env/lib/python3.11/site-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch-geometric) (3.11.10)\n",
            "Requirement already satisfied: fsspec in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch-geometric) (2024.9.0)\n",
            "Requirement already satisfied: jinja2 in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch-geometric) (6.0.0)\n",
            "Requirement already satisfied: pyparsing in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from aiohttp->torch-geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./mambaforge/envs/env/lib/python3.11/site-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./mambaforge/envs/env/lib/python3.11/site-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./mambaforge/envs/env/lib/python3.11/site-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from aiohttp->torch-geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./mambaforge/envs/env/lib/python3.11/site-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./mambaforge/envs/env/lib/python3.11/site-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./mambaforge/envs/env/lib/python3.11/site-packages (from requests->torch-geometric) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./mambaforge/envs/env/lib/python3.11/site-packages (from requests->torch-geometric) (2024.6.2)\n",
            "Requirement already satisfied: torchvision in ./mambaforge/envs/env/lib/python3.11/site-packages (0.18.1)\n",
            "Requirement already satisfied: numpy in ./mambaforge/envs/env/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch in ./mambaforge/envs/env/lib/python3.11/site-packages (from torchvision) (2.3.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: filelock in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch->torchvision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch->torchvision) (1.12.1)\n",
            "Requirement already satisfied: networkx in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch->torchvision) (2024.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from jinja2->torch->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from sympy->torch->torchvision) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "torch_version = str(torch.__version__)\n",
        "# scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "# sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "# !pip install torch-scatter -f $scatter_src\n",
        "# !pip install torch-sparse -f $sparse_src\n",
        "!pip install torch-geometric\n",
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b3b3c18-56ac-47c1-970f-2b0916acd709",
      "metadata": {
        "tags": [],
        "id": "4b3b3c18-56ac-47c1-970f-2b0916acd709",
        "outputId": "a22ef598-1de6-4ea2-ae18-3f0f57aa720e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.6.1'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch_geometric\n",
        "torch_geometric.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7169a000-e8dc-4350-af5d-883d4e1aefdc",
      "metadata": {
        "tags": [],
        "id": "7169a000-e8dc-4350-af5d-883d4e1aefdc",
        "outputId": "4315d0bf-16db-41ba-d66c-ce5830db0397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in ./mambaforge/envs/env/lib/python3.11/site-packages (3.2.0)\n",
            "Requirement already satisfied: transformers in ./mambaforge/envs/env/lib/python3.11/site-packages (4.47.0)\n",
            "Requirement already satisfied: pcst_fast in ./mambaforge/envs/env/lib/python3.11/site-packages (1.0.10)\n",
            "Requirement already satisfied: sentencepiece in ./mambaforge/envs/env/lib/python3.11/site-packages (0.2.0)\n",
            "Requirement already satisfied: accelerate in ./mambaforge/envs/env/lib/python3.11/site-packages (1.2.0)\n",
            "Requirement already satisfied: filelock in ./mambaforge/envs/env/lib/python3.11/site-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in ./mambaforge/envs/env/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in ./mambaforge/envs/env/lib/python3.11/site-packages (from datasets) (2.1.1)\n",
            "Requirement already satisfied: requests>=2.32.2 in ./mambaforge/envs/env/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in ./mambaforge/envs/env/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in ./mambaforge/envs/env/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in ./mambaforge/envs/env/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in ./mambaforge/envs/env/lib/python3.11/site-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from datasets) (0.26.5)\n",
            "Requirement already satisfied: packaging in ./mambaforge/envs/env/lib/python3.11/site-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./mambaforge/envs/env/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./mambaforge/envs/env/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./mambaforge/envs/env/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in ./mambaforge/envs/env/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: pybind11>=2.1.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from pcst_fast) (2.13.6)\n",
            "Requirement already satisfied: psutil in ./mambaforge/envs/env/lib/python3.11/site-packages (from accelerate) (6.0.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from accelerate) (2.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./mambaforge/envs/env/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./mambaforge/envs/env/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./mambaforge/envs/env/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./mambaforge/envs/env/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./mambaforge/envs/env/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./mambaforge/envs/env/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./mambaforge/envs/env/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./mambaforge/envs/env/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
            "Requirement already satisfied: sympy in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in ./mambaforge/envs/env/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./mambaforge/envs/env/lib/python3.11/site-packages (from pandas->datasets) (2.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./mambaforge/envs/env/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in ./mambaforge/envs/env/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in ./mambaforge/envs/env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./mambaforge/envs/env/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers pcst_fast sentencepiece accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "740fa54b-75b4-416e-9d60-543aff3fb916",
      "metadata": {
        "tags": [],
        "id": "740fa54b-75b4-416e-9d60-543aff3fb916"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "import argparse\n",
        "import gc\n",
        "import math\n",
        "import os.path as osp\n",
        "import re\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch_geometric import seed_everything\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.datasets import WebQSPDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn.models import GAT, GRetriever, GraphSAGE, GIN\n",
        "from torch_geometric.nn import GCNConv, TransformerConv, GATConv\n",
        "from torch_geometric.nn.nlp import LLM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e957f05-536e-45bc-acc4-625d9e911ed6",
      "metadata": {
        "tags": [],
        "id": "7e957f05-536e-45bc-acc4-625d9e911ed6"
      },
      "outputs": [],
      "source": [
        "def save_model_state(model, path):\n",
        "    model_state = model.state_dict()\n",
        "    params_dict = {key : value.requires_grad for\n",
        "                 (key, value) in model.named_parameters() }\n",
        "\n",
        "    for key in list(model_state.keys()):\n",
        "        if key in params_dict.keys() and params_dict[key] == False:\n",
        "            del model_state[key]\n",
        "\n",
        "    torch.save(model_state, path)\n",
        "\n",
        "\n",
        "def loadModelWeights(model, from_path):\n",
        "    weightsState = torch.load(from_path)\n",
        "    model.load_state_dict(weightsState)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def getLoss(model, batch, name) -> Tensor:\n",
        "\n",
        "    return model(batch.question, batch.x,\n",
        "                batch.edge_index, batch.batch,\n",
        "                batch.label, batch.edge_attr,\n",
        "                batch.desc)\n",
        "\n",
        "\n",
        "def runInference(model, batch, name):\n",
        "    return model.inference(batch.question, batch.x,\n",
        "                           batch.edge_index, batch.batch,\n",
        "                            batch.edge_attr, batch.desc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5b7aeda-b159-48b4-ad91-5c7168763ab1",
      "metadata": {
        "tags": [],
        "id": "e5b7aeda-b159-48b4-ad91-5c7168763ab1"
      },
      "outputs": [],
      "source": [
        "def getLearningRate(param_group, LR, epoch):\n",
        "\n",
        "    num_epochs = 2\n",
        "\n",
        "    min_lr = 5e-6\n",
        "    if epoch < 1:\n",
        "        lr = LR\n",
        "    else:\n",
        "        lr = min_lr + (LR - min_lr) * 0.5 * (\n",
        "            1.0 + math.cos(math.pi * (epoch - 1) /\n",
        "                            (num_epochs - 1)))\n",
        "    param_group['lr'] = lr\n",
        "    return lr\n",
        "\n",
        "def loadWebQSPDataset():\n",
        "    train_dataset = torch.load('train_data.pt')\n",
        "    validation_dataset = torch.load('val_data.pt')\n",
        "\n",
        "    return (train_dataset, validation_dataset)\n",
        "\n",
        "\n",
        "def compute_metrics(eval_output):\n",
        "    df = pd.concat([pd.DataFrame(d) for d in eval_output])\n",
        "    all_hit = []\n",
        "    all_precision = []\n",
        "    all_recall = []\n",
        "    all_f1 = []\n",
        "    for pred, label in zip(df.pred.tolist(), df.label.tolist()):\n",
        "        try:\n",
        "            pred = pred.split('[/s]')[0].strip().split('|')\n",
        "            hit = re.findall(pred[0], label)\n",
        "            all_hit.append(len(hit) > 0)\n",
        "\n",
        "            label = label.split('|')\n",
        "            matches = set(pred).intersection(set(label))\n",
        "            precision = len(matches) / len(set(pred))\n",
        "            recall = len(matches) / len(set(label))\n",
        "            if recall + precision == 0:\n",
        "                f1 = 0\n",
        "            else:\n",
        "                f1 = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "            all_precision.append(precision)\n",
        "            all_recall.append(recall)\n",
        "            all_f1.append(f1)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f'Label: {label}')\n",
        "            print(f'Pred: {pred}')\n",
        "            print(f'Exception: {e}')\n",
        "            print('------------------')\n",
        "\n",
        "    hit = sum(all_hit) / len(all_hit)\n",
        "    precision = sum(all_precision) / len(all_precision)\n",
        "    recall = sum(all_recall) / len(all_recall)\n",
        "    f1 = sum(all_f1) / len(all_f1)\n",
        "\n",
        "    print(f'Hit: {hit:.4f}')\n",
        "    print(f'Precision: {precision:.4f}')\n",
        "    print(f'Recall: {recall:.4f}')\n",
        "    print(f'F1: {f1:.4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff2443df-792d-4e96-ab32-af1dd9ff8068",
      "metadata": {
        "tags": [],
        "id": "ff2443df-792d-4e96-ab32-af1dd9ff8068",
        "outputId": "8e20a50b-cf54-4071-91c2-864e3c48ad46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "dict_keys(['x', 'edge_index', 'edge_attr', 'question', 'label', 'desc'])\n",
            "<class 'dict'>\n",
            "dict_keys(['x', 'edge_index', 'edge_attr', 'question', 'label', 'desc'])\n",
            "<class 'torch_geometric.data.data.Data'>\n",
            "_____\n",
            "<class 'torch_geometric.data.data.Data'>\n",
            "<class 'torch_geometric.data.data.Data'>\n",
            "<class 'torch_geometric.data.data.Data'>\n",
            "3\n",
            "the step is: \n",
            "0\n",
            "<class 'abc.DataBatch'>\n",
            "the step is: \n",
            "1\n",
            "<class 'abc.DataBatch'>\n",
            "the step is: \n",
            "2\n",
            "<class 'abc.DataBatch'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/tmp/ipykernel_538356/1312087033.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  valid_data_trial = torch.load(\"val_data.pt\")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#print(len(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a70cc987-5053-44b0-b587-cf3a17a3f478",
      "metadata": {
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "4d30fea74c354cf7910ef4149bdcbbd8",
            "2c6eb35aab3d4d2182232843b5f9950d",
            "e81981c570e14e1f90f6c9d3fc2e3cba",
            "c0d971abd1c4485880409703cb178307",
            "ea2f983eeee7466c85ab436508179d4e",
            "668c9aeb51b4479283033939df2452f1",
            "9129a78bb7e84318b2e608d9ba7175fc",
            "278374767cd24c708a0576bbeb6d420b",
            "0dc030536f374c58a9689f97702c08c4",
            "2d92bed2d9d94462b2db53feafb9be4f",
            "92b1fbb6bcdb4c98b5bf1bea75149974",
            "705e509a644945e1b275dfa9b4436dc8",
            "62431acd59314eaa9cd2dc9796f94d17",
            "2158097904a647ff846881fd91ee3986",
            "eb516ca972d54160af5c35bd83c3580d",
            "84082479159f4bab8139b954eabf1a67",
            "587e9504424544de8e909f2faba5f445"
          ]
        },
        "id": "a70cc987-5053-44b0-b587-cf3a17a3f478",
        "outputId": "e59cb161-1345-4381-d8f5-0436dd696f78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d30fea74c354cf7910ef4149bdcbbd8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/900 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c6eb35aab3d4d2182232843b5f9950d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "(…)-00000-of-00002-d810a36ed97bc2cc.parquet:   0%|          | 0.00/154M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e81981c570e14e1f90f6c9d3fc2e3cba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "(…)-00001-of-00002-e53244e71082a392.parquet:   0%|          | 0.00/155M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0d971abd1c4485880409703cb178307",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "(…)-00000-of-00001-6ee6adc5b154643a.parquet:   0%|          | 0.00/24.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea2f983eeee7466c85ab436508179d4e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "(…)-00000-of-00002-9ee8d68f7d951e1f.parquet:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "668c9aeb51b4479283033939df2452f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "(…)-00001-of-00002-773a7b8213e159f5.parquet:   0%|          | 0.00/93.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9129a78bb7e84318b2e608d9ba7175fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/2826 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "278374767cd24c708a0576bbeb6d420b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/246 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0dc030536f374c58a9689f97702c08c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/1628 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d92bed2d9d94462b2db53feafb9be4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92b1fbb6bcdb4c98b5bf1bea75149974",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/328 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "705e509a644945e1b275dfa9b4436dc8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62431acd59314eaa9cd2dc9796f94d17",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2158097904a647ff846881fd91ee3986",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb516ca972d54160af5c35bd83c3580d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84082479159f4bab8139b954eabf1a67",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "587e9504424544de8e909f2faba5f445",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 2826/2826 [5:12:22<00:00,  6.63s/it]\n",
            "100%|█████████████████████████████████████████| 246/246 [27:14<00:00,  6.64s/it]\n",
            " 89%|████████████████████████████████▊    | 1446/1628 [2:42:50<18:05,  5.97s/it]"
          ]
        }
      ],
      "source": [
        "datasetPath = \"./dataset_qsp/\"\n",
        "train_dataset2 = WebQSPDataset(datasetPath, split='train')\n",
        "val_dataset2 = WebQSPDataset(datasetPath, split='val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0710d19a-33dc-4580-ac5b-5d79d667fd28",
      "metadata": {
        "tags": [],
        "id": "0710d19a-33dc-4580-ac5b-5d79d667fd28"
      },
      "outputs": [],
      "source": [
        "datasetPath2 = \"./dataset_qsp/\"\n",
        "dataset_train = WebQSPDataset(datasetPath2, split = 'train')\n",
        "dataset_valid = WebQSPDataset(datasetPath2, split = 'val')\n",
        "dataset_test = WebQSPDataset(datasetPath2, split = 'test')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ae22e3c-c1ac-4e48-9c98-c75fd481fc2e",
      "metadata": {
        "tags": [],
        "id": "7ae22e3c-c1ac-4e48-9c98-c75fd481fc2e"
      },
      "outputs": [],
      "source": [
        "def train_model(name, gnn, epoch_count, hidden_channel_size, gnn_layer_count, batch_size, validation_batch_size, lr, checkpointing = True, load_checkpoint = False):\n",
        "\n",
        "    seed_everything(99)\n",
        "\n",
        "    # Load datasets for train/validation and load their loaders\n",
        "    train_loader = DataLoader(dataset_train, batch_size = batch_size, drop_last = True, pin_memory = True, shuffle = True)\n",
        "    val_loader = DataLoader(dataset_valid, batch_size = validation_batch_size, drop_last = False, pin_memory = True, shuffle=False)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Model Building\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    hf_token = \"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\"\n",
        "\n",
        "    if gnn == \"GAT\":\n",
        "        gnn1 = GAT(in_channels = 1024, hidden_channels = hidden_channel_size,\n",
        "              out_channels = 1024, num_layers = gnn_layer_count,\n",
        "              heads = 4, dropout=0.1)\n",
        "    elif gnn == \"GraphSAGE\":\n",
        "        gnn1 = GraphSAGE(in_channels = 1024,\n",
        "              hidden_channels = hidden_channel_size, num_layers = gnn_layer_count,\n",
        "              out_channels = 1024, dropout=0.1)\n",
        "    elif gnn == \"GIN\":\n",
        "        gnn1 = GIN(in_channels = 1024,\n",
        "              hidden_channels = hidden_channel_size, num_layers = gnn_layer_count,\n",
        "              out_channels = 1024, dropout=0.1)\n",
        "\n",
        "    llm1 = LLM(model_name='TinyLlama/TinyLlama-1.1B-Chat-v0.1', num_params = 1)\n",
        "    # llm2 = LLM(model_name='meta-llama/Llama-2-7b-chat-hf', num_params=7, kwargs={\"use_auth_token\": hf_token})\n",
        "\n",
        "    model = GRetriever(llm = llm1, gnn = gnn1, mlp_out_channels = 2048)\n",
        "    # model2 = GRetriever(llm = llm2, gnn = gnn1)\n",
        "\n",
        "    modulo = 2\n",
        "\n",
        "    # Begin training\n",
        "    parameters = [x for _, x in model.named_parameters() if x.requires_grad]\n",
        "    optimizer = torch.optim.AdamW(  [{ 'params' : parameters, 'lr' : lr, 'weight_decay' : 0.05 }],\n",
        "                                    betas = (0.9, 0.95)  )\n",
        "\n",
        "    # if load_checkpoint:\n",
        "    #     PATH = f'{name}_best_val_loss_INF_ckpt.pt'\n",
        "    #     checkpoint = torch.load(PATH, weights_only=True)\n",
        "    #     model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    #     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    #     last_epoch = checkpoint['epoch']\n",
        "    #     loss = checkpoint['loss']\n",
        "    #     print(f'best epoch: {best_epoch}')\n",
        "    # else:\n",
        "\n",
        "\n",
        "    best_epoch = 0\n",
        "    best_val_loss = float('inf')\n",
        "    for epoch in range(epoch_count):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        if epoch == 0:\n",
        "            #print(f\"Total Preparation Time: {time.time() - start_time:2f}s\")\n",
        "            start_time = time.time()\n",
        "            print(\"Training beginning...\")\n",
        "        epoch_str = f'Epoch: {epoch + 1}|{epoch_count}'\n",
        "        loader = tqdm(train_loader, desc=epoch_str)\n",
        "        for step, batch in enumerate(loader):\n",
        "            optimizer.zero_grad()\n",
        "            loss = getLoss(model, batch, 'gnn_llm')\n",
        "            loss.backward()\n",
        "\n",
        "            clip_grad_norm_(optimizer.param_groups[0]['params'], 0.1)\n",
        "\n",
        "            if (step + 1) % modulo == 0:\n",
        "                getLearningRate(optimizer.param_groups[0], lr,\n",
        "                                     step / len(train_loader) + epoch)\n",
        "\n",
        "            optimizer.step()\n",
        "            epoch_loss = epoch_loss + float(loss)\n",
        "\n",
        "            if (step + 1) % modulo == 0:\n",
        "                lr = optimizer.param_groups[0]['lr']\n",
        "        train_loss = epoch_loss / len(train_loader)\n",
        "        print(epoch_str + f', Train Loss: {train_loss:4f}')\n",
        "\n",
        "        val_loss = 0\n",
        "        eval_output = []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for step, batch in enumerate(val_loader):\n",
        "                loss = getLoss(model, batch, 'gnn_llm')\n",
        "                val_loss += loss.item()\n",
        "            val_loss = val_loss / len(val_loader)\n",
        "            print(epoch_str + f\", Val Loss: {val_loss:4f}\")\n",
        "        if checkpointing and val_loss < best_val_loss:\n",
        "            print(\"Checkpointing best model...\")\n",
        "            best_val_loss = val_loss\n",
        "            best_epoch = epoch\n",
        "            save_model_state(model, f'{name}_best_val_loss_ckpt.pt')\n",
        "            torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'best_val_loss': best_val_loss,\n",
        "            'best_epoch': best_epoch\n",
        "            }, f'{name}_best_val_loss_INF_ckpt.pt')\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_max_memory_allocated()\n",
        "\n",
        "    if checkpointing and best_epoch != epoch_count - 1:\n",
        "        print(\"Loading best checkpoint...\")\n",
        "        model = loadModelWeights(\n",
        "            model,\n",
        "            f'{name}_best_val_loss_ckpt.pt',\n",
        "        )\n",
        "\n",
        "    test_loader = DataLoader(dataset_test, batch_size = validation_batch_size, drop_last = False, pin_memory = True, shuffle=False)\n",
        "\n",
        "    model.eval()\n",
        "    eval_output = []\n",
        "    print(\"Final evaluation...\")\n",
        "    progress_bar_test = tqdm(range(len(test_loader)))\n",
        "    for step, batch in enumerate(test_loader):\n",
        "        with torch.no_grad():\n",
        "            pred = runInference(model, batch, name)\n",
        "            eval_data = {\n",
        "                'pred': pred,\n",
        "                'question': batch.question,\n",
        "                'desc': batch.desc,\n",
        "                'label': batch.label\n",
        "            }\n",
        "            eval_output.append(eval_data)\n",
        "        progress_bar_test.update(1)\n",
        "\n",
        "    compute_metrics(eval_output)\n",
        "    print(f\"Total Training Time: {time.time() - start_time:2f}s\")\n",
        "    save_model_state(model, f'{name}.pt')\n",
        "    torch.save(eval_output, f'{name}_eval_outs.pt')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae0e3f79-112d-4c4f-84fe-17863655d5fc",
      "metadata": {
        "tags": [],
        "id": "ae0e3f79-112d-4c4f-84fe-17863655d5fc"
      },
      "outputs": [],
      "source": [
        "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cca816e-ce22-4241-aa76-0805162aeaf7",
      "metadata": {
        "tags": [],
        "id": "5cca816e-ce22-4241-aa76-0805162aeaf7",
        "outputId": "bd643130-d027-4b67-8399-06ff4804bde2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GAT_4lyr_4batchsz_512hiddim_50eps\n",
            "Setting up 'TinyLlama/TinyLlama-1.1B-Chat-v0.1' with configuration: {'revision': 'main', 'max_memory': {0: '60GiB'}, 'low_cpu_mem_usage': True, 'device_map': 'auto', 'torch_dtype': torch.bfloat16}\n",
            "Training beginning...\n",
            "Epoch: 1|50: 100%|████████████████████████████| 706/706 [02:26<00:00,  4.81it/s]\n",
            "Epoch: 1|50, Train Loss: 1.410534\n",
            "Epoch: 1|50, Val Loss: 1.314335\n",
            "Checkpointing best model...\n",
            "Epoch: 2|50: 100%|████████████████████████████| 706/706 [02:28<00:00,  4.76it/s]\n",
            "Epoch: 2|50, Train Loss: 1.166692\n",
            "Epoch: 2|50, Val Loss: 1.277962\n",
            "Checkpointing best model...\n",
            "Epoch: 3|50: 100%|████████████████████████████| 706/706 [02:28<00:00,  4.76it/s]\n",
            "Epoch: 3|50, Train Loss: 1.128714\n",
            "Epoch: 3|50, Val Loss: 1.261932\n",
            "Checkpointing best model...\n",
            "Epoch: 4|50: 100%|████████████████████████████| 706/706 [02:27<00:00,  4.78it/s]\n",
            "Epoch: 4|50, Train Loss: 1.103605\n",
            "Epoch: 4|50, Val Loss: 1.254910\n",
            "Checkpointing best model...\n",
            "Epoch: 5|50: 100%|████████████████████████████| 706/706 [02:27<00:00,  4.79it/s]\n",
            "Epoch: 5|50, Train Loss: 1.080899\n",
            "Epoch: 5|50, Val Loss: 1.248371\n",
            "Checkpointing best model...\n",
            "Epoch: 6|50: 100%|████████████████████████████| 706/706 [02:27<00:00,  4.78it/s]\n",
            "Epoch: 6|50, Train Loss: 1.064121\n",
            "Epoch: 6|50, Val Loss: 1.243105\n",
            "Checkpointing best model...\n",
            "Epoch: 7|50: 100%|████████████████████████████| 706/706 [02:27<00:00,  4.79it/s]\n",
            "Epoch: 7|50, Train Loss: 1.055044\n",
            "Epoch: 7|50, Val Loss: 1.243180\n",
            "Epoch: 8|50: 100%|████████████████████████████| 706/706 [02:26<00:00,  4.81it/s]\n",
            "Epoch: 8|50, Train Loss: 1.041043\n",
            "Epoch: 8|50, Val Loss: 1.238213\n",
            "Checkpointing best model...\n",
            "Epoch: 9|50: 100%|████████████████████████████| 706/706 [02:28<00:00,  4.75it/s]\n",
            "Epoch: 9|50, Train Loss: 1.028600\n",
            "Epoch: 9|50, Val Loss: 1.237652\n",
            "Checkpointing best model...\n",
            "Epoch: 10|50: 100%|███████████████████████████| 706/706 [02:29<00:00,  4.71it/s]\n",
            "Epoch: 10|50, Train Loss: 1.022428\n",
            "Epoch: 10|50, Val Loss: 1.236031\n",
            "Checkpointing best model...\n",
            "Epoch: 11|50: 100%|███████████████████████████| 706/706 [02:28<00:00,  4.75it/s]\n",
            "Epoch: 11|50, Train Loss: 1.011157\n",
            "Epoch: 11|50, Val Loss: 1.235138\n",
            "Checkpointing best model...\n",
            "Epoch: 12|50: 100%|███████████████████████████| 706/706 [02:29<00:00,  4.72it/s]\n",
            "Epoch: 12|50, Train Loss: 1.011566\n",
            "Epoch: 12|50, Val Loss: 1.232895\n",
            "Checkpointing best model...\n",
            "Epoch: 13|50: 100%|███████████████████████████| 706/706 [02:30<00:00,  4.68it/s]\n",
            "Epoch: 13|50, Train Loss: 0.999181\n",
            "Epoch: 13|50, Val Loss: 1.234516\n",
            "Epoch: 14|50: 100%|███████████████████████████| 706/706 [02:29<00:00,  4.73it/s]\n",
            "Epoch: 14|50, Train Loss: 1.002095\n",
            "Epoch: 14|50, Val Loss: 1.234419\n",
            "Epoch: 15|50: 100%|███████████████████████████| 706/706 [02:29<00:00,  4.73it/s]\n",
            "Epoch: 15|50, Train Loss: 1.001395\n",
            "Epoch: 15|50, Val Loss: 1.239082\n",
            "Epoch: 16|50: 100%|███████████████████████████| 706/706 [02:30<00:00,  4.69it/s]\n",
            "Epoch: 16|50, Train Loss: 1.000374\n",
            "Epoch: 16|50, Val Loss: 1.236205\n",
            "Epoch: 17|50: 100%|███████████████████████████| 706/706 [02:30<00:00,  4.71it/s]\n",
            "Epoch: 17|50, Train Loss: 0.995231\n",
            "Epoch: 17|50, Val Loss: 1.237408\n",
            "Epoch: 18|50: 100%|███████████████████████████| 706/706 [02:31<00:00,  4.67it/s]\n",
            "Epoch: 18|50, Train Loss: 0.978777\n",
            "Epoch: 18|50, Val Loss: 1.236757\n",
            "Epoch: 19|50: 100%|███████████████████████████| 706/706 [02:31<00:00,  4.66it/s]\n",
            "Epoch: 19|50, Train Loss: 0.992150\n",
            "Epoch: 19|50, Val Loss: 1.240261\n",
            "Epoch: 20|50: 100%|███████████████████████████| 706/706 [02:30<00:00,  4.69it/s]\n",
            "Epoch: 20|50, Train Loss: 0.982846\n",
            "Epoch: 20|50, Val Loss: 1.242246\n",
            "Loading best checkpoint...\n",
            "Final evaluation...\n",
            "100%|█████████████████████████████████████████| 407/407 [04:30<00:00,  1.51it/s]\n",
            "Hit: 0.4496\n",
            "Precision: 0.3598\n",
            "Recall: 0.3049\n",
            "F1: 0.2961\n",
            "Total Training Time: 8153.486252s\n"
          ]
        }
      ],
      "source": [
        "batch_size = 4\n",
        "validation_batch_size = 4\n",
        "lr = 1e-5\n",
        "checkpointing = True\n",
        "epoch_count = 50\n",
        "hidden_channel_size = 512\n",
        "gnn_layer_count = 4\n",
        "gnn = 'GAT'\n",
        "name = f'{gnn}_{gnn_layer_count}lyr_{batch_size}batchsz_{hidden_channel_size}hiddim_{epoch_count}eps'\n",
        "print(name)\n",
        "train_model(name, gnn, epoch_count, hidden_channel_size, gnn_layer_count, batch_size, validation_batch_size, lr, checkpointing, load_checkpoint=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "addbf78e-66ce-4f67-8593-6684370097a4",
      "metadata": {
        "id": "addbf78e-66ce-4f67-8593-6684370097a4"
      },
      "outputs": [],
      "source": [
        "batch_size = 4\n",
        "validation_batch_size = 4\n",
        "lr = 1e-5\n",
        "checkpointing = True\n",
        "epoch_count = 50\n",
        "hidden_channel_size = 512\n",
        "gnn_layer_count = 4\n",
        "gnn = 'GraphSAGE'\n",
        "name = f'{gnn}_{gnn_layer_count}lyr_{batch_size}batchsz_{hidden_channel_size}hiddim_{epoch_count}eps'\n",
        "print(name)\n",
        "\n",
        "train_model(name, gnn, epoch_count, hidden_channel_size, gnn_layer_count, batch_size, validation_batch_size, lr, checkpointing, load_checkpoint = False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c378099-8d93-4ef3-abb4-e94c5ae07309",
      "metadata": {
        "id": "4c378099-8d93-4ef3-abb4-e94c5ae07309"
      },
      "outputs": [],
      "source": [
        "batch_size = 4\n",
        "validation_batch_size = 4\n",
        "lr = 1e-5\n",
        "checkpointing = True\n",
        "epoch_count = 50\n",
        "hidden_channel_size = 512\n",
        "gnn_layer_count = 4\n",
        "gnn = 'GIN'\n",
        "name = f'{gnn}_{gnn_layer_count}lyr_{batch_size}batchsz_{hidden_channel_size}hiddim_{epoch_count}eps'\n",
        "print(name)\n",
        "\n",
        "train_model(name, gnn, epoch_count, hidden_channel_size, gnn_layer_count, batch_size, validation_batch_size, lr, checkpointing, load_checkpoint=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "323602d6-fcf7-4d0c-9142-66e0002382e9",
      "metadata": {
        "id": "323602d6-fcf7-4d0c-9142-66e0002382e9",
        "outputId": "880a4bbb-35ce-4636-be32-3ffd853f3247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: protobuf in ./mambaforge/envs/env/lib/python3.11/site-packages (5.29.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install protobuf"
      ]
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "conda-base-py",
      "name": "workbench-notebooks.m126",
      "type": "gcloud",
      "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}